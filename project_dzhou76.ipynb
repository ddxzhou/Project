{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd05a8c4beeb57ac70324e99c0d9e7e52dfb0beb04b4896587b0b18c4662d4bbf1a",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import Levenshtein as lev\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "source": [
    "## 1. Data Reading"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data as pandas dataframes\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "rtable_df = pd.read_csv(\"rtable.csv\")\n",
    "ltable_df = pd.read_csv(\"ltable.csv\")\n",
    "\n",
    "rtable_df.rename(columns = {\"id\": \"r_id\", \"title\": \"r_title\", \"category\": \"r_category\", \"brand\":\"r_brand\", \"modelno\":\"r_modelno\",\"price\":\"r_price\"}, inplace = True)\n",
    "ltable_df.rename(columns = {\"id\": \"l_id\", \"title\": \"l_title\", \"category\": \"l_category\", \"brand\":\"l_brand\", \"modelno\":\"l_modelno\",\"price\":\"l_price\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data(train_df):\n",
    "    training_set = []\n",
    "    labels = []\n",
    "    for row_num in range(len(train_df)): # row_num is equal to id number\n",
    "        i = train_df.iloc[row_num,:].loc[\"ltable_id\"]\n",
    "        j = train_df.iloc[row_num,:].loc[\"rtable_id\"]\n",
    "        k = train_df.iloc[row_num,:].loc[\"label\"]\n",
    "        training_set.append((i,j))\n",
    "        labels.append(k)\n",
    "    return training_set, labels\n",
    "\n",
    "training_set, labels = training_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2training(training_set, ltable, rtable):\n",
    " \n",
    "    ltable_ids = []\n",
    "    rtable_ids = []\n",
    "    for i,j in training_set: # each tuple pair\n",
    "        ltable_ids.append(i)\n",
    "        rtable_ids.append(j)\n",
    "\n",
    "    ltable = ltable.loc[ltable_ids,:]\n",
    "    rtable = rtable.loc[rtable_ids,:]\n",
    "\n",
    "    ltable.reset_index(inplace=True)\n",
    "    rtable.reset_index(inplace=True)\n",
    "\n",
    "    training_df = pd.concat([ltable, rtable], axis = 1)\n",
    "    return training_df\n",
    "\n",
    "training_df = add2training(training_set, ltable_df, rtable_df)"
   ]
  },
  {
   "source": [
    "## 2. Blocking Step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtable_df[\"key\"] = 0\n",
    "ltable_df[\"key\"] = 0\n",
    "df_cartesian = rtable_df.merge(ltable_df, how = \"outer\") # cartesian product on the 2 dataframes to get all possible combinations and their corresponding attribute info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cartesian.drop(columns = [\"key\"],inplace = True)\n",
    "df_cartesian[\"Keep\"] = \"No\" # create a new column to determine whether or not to keep row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cartesian['r_brand'] = df_cartesian['r_brand'].astype(str)\n",
    "df_cartesian['l_brand'] = df_cartesian['l_brand'].astype(str)\n",
    "\n",
    "# Make sure all brand names are lower case\n",
    "df_cartesian[\"r_brand\"] = df_cartesian[\"r_brand\"].str.lower()\n",
    "df_cartesian[\"l_brand\"] = df_cartesian[\"l_brand\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_from_brand = [\" \", \"-\"]\n",
    "for i in remove_from_brand:\n",
    "    # remove empty spaces and punctuation in brand names\n",
    "    df_cartesian[\"l_brand\"] = df_cartesian[\"l_brand\"].apply(lambda x: str(x).replace(i,\"\"))\n",
    "    df_cartesian[\"r_brand\"] = df_cartesian[\"r_brand\"].apply(lambda x: str(x).replace(i,\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_cartesian[\"l_brand\"] == df_cartesian[\"r_brand\"]\n",
    "df_cartesian.loc[mask,\"Keep\"] = \"Yes\" # if brand names are identical (character by character, word for word), change \"No\" in Keep column to \"Yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_df = df_cartesian[df_cartesian[\"Keep\"] == \"Yes\"] # keep only the rows where the brand name is the same\n",
    "candidate_df.set_index([\"l_id\",\"r_id\"], inplace = True) # create a multi-index\n",
    "cand_set = candidate_df.index # number of combinations reduced to 258,219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/daisyzhou/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "candidate_df.reset_index(inplace = True)\n",
    "candidate_df.drop([\"Keep\"], axis = 1, inplace = True) # drop the \"Keep\" column because not needed for features section"
   ]
  },
  {
   "source": [
    "## 3. Feature Engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fuzz_ratio(row,i):\n",
    "    fuzz_l = row[\"l_\" + i].lower()\n",
    "    fuzz_r = row[\"r_\" + i].lower()\n",
    "    fuzz_num = fuzz.token_set_ratio(fuzz_l,fuzz_r)\n",
    "    return fuzz_num\n",
    "\n",
    "def levenshtein_dist(row,i):\n",
    "    ld_l = row[\"l_\" + i].lower()\n",
    "    ld_r = row[\"r_\" + i].lower()\n",
    "    lev_dist = lev.distance(ld_l,ld_r)\n",
    "    return lev_dist\n",
    "\n",
    "def jaccard_similarity(row,i):\n",
    "    js_l = row[\"l_\" + i].lower().split()\n",
    "    js_r = row[\"r_\" + i].lower().split()\n",
    "    numer = len(set(js_l).intersection(set(js_r)))\n",
    "    jaccard_num =  numer/max(len(js_l),len(js_r))\n",
    "    return jaccard_num\n",
    "\n",
    "def rate_num(row,i): # matching the numbers in the string for each attribute\n",
    "    str_l = row[\"l_\" + i].lower()\n",
    "    str_r = row[\"r_\" + i].lower()\n",
    "    num_l = re.findall(r\"[0-9]+\",str_l)\n",
    "    num_r = re.findall(r\"[0-9]+\",str_r)\n",
    "    if len(num_l) == 0 & len(num_r) == 0:\n",
    "        rate = 0\n",
    "    else:\n",
    "        rate = len(set(num_l).intersection(set(num_r)))/len(set(num_l).union(set(num_r)))\n",
    "    return rate\n",
    "    \n",
    "def feature_engr(df4feature):\n",
    "    df4feature = df4feature.astype(str)\n",
    "    attributes = [\"title\", \"category\", \"brand\", \"modelno\", \"price\"]\n",
    "    feature_vals = []\n",
    "    for i in attributes:\n",
    "        jaccard_num = df4feature.apply(jaccard_similarity, i = i, axis = 1)\n",
    "        lev_dist = df4feature.apply(levenshtein_dist, i = i, axis = 1)\n",
    "        fuzz_num = df4feature.apply(fuzz_ratio, i = i, axis = 1)\n",
    "        match_nums = df4feature.apply(rate_num, i = i, axis = 1)\n",
    "        feature_vals.append(jaccard_num)\n",
    "        feature_vals.append(lev_dist)\n",
    "        feature_vals.append(fuzz_num)\n",
    "        feature_vals.append(match_nums)\n",
    "\n",
    "    features_arr = np.array(feature_vals).T\n",
    "    return features_arr\n",
    "\n",
    "candidate_features = feature_engr(candidate_df)\n",
    "training_features = feature_engr(training_df)"
   ]
  },
  {
   "source": [
    "## 4. Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model and predict, using Logistic Regression classification model\n",
    "clf = LogisticRegression(class_weight = \"balanced\",random_state = 0, max_iter = 100000)\n",
    "clf.fit(training_features,labels)\n",
    "y_pred = clf.predict(candidate_features)\n",
    "# number of matches is 2316"
   ]
  },
  {
   "source": [
    "## 5. Generating Output and Writing to CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert matches to list of tuples\n",
    "cand_tuples = []\n",
    "model_matches = candidate_df.loc[y_pred == 1, [\"l_id\", \"r_id\"]]\n",
    "cand_tuples = [(row.l_id, row.r_id) for row in model_matches.itertuples()] # get the (l_id, r_id) pairs where there is a match from running the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the matches from training set\n",
    "matched_entries = train_df[train_df[\"label\"] == 1]\n",
    "matched_tups = [(i.ltable_id, i.rtable_id) for i in matched_entries.itertuples()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove matches in result if they appeared as a match in the training set\n",
    "cand_tuples = set(cand_tuples)\n",
    "for tup in matched_tups:\n",
    "    if tup in cand_tuples:\n",
    "        cand_tuples.remove(tup) # number of matches left: 2136 --> 1801\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write matches from Logistic Regression model to CSV file\n",
    "with open(\"MLproject_output.csv\", \"w\") as fout:\n",
    "    writer = csv.writer(fout, delimiter = \",\")\n",
    "    writer.writerow([\"ltable_id\",\"rtable_id\"])\n",
    "    for tup in cand_tuples:\n",
    "        writer.writerow(tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}